import numpy as np
import pandas as pd
from tqdm import tqdm
import pickle
import os
import random
import collections
import faiss
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# å®šä¹‰æ•°æ®é›†ç±»
class YouTubeDNNDataset(Dataset):
    def __init__(self, user_ids, item_seqs, target_items, labels, seq_lens, max_len=30):
        self.user_ids = torch.LongTensor(user_ids)
        self.target_items = torch.LongTensor(target_items)
        self.labels = torch.FloatTensor(labels)
        self.seq_lens = torch.LongTensor(np.minimum(seq_lens, max_len))  # ç¡®ä¿ä¸è¶…è¿‡max_len
        self.max_len = max_len
        
        # é¢„å¤„ç†æ‰€æœ‰åºåˆ—ï¼Œç¡®ä¿é•¿åº¦ä¸€è‡´
        self.padded_seqs = []
        for seq in item_seqs:
            if len(seq) > max_len:
                # æˆªæ–­è¿‡é•¿çš„åºåˆ—
                padded_seq = seq[:max_len]
            else:
                # å¡«å……è¿‡çŸ­çš„åºåˆ—
                padded_seq = seq + [0] * (max_len - len(seq))
            self.padded_seqs.append(padded_seq)
        self.padded_seqs = torch.LongTensor(self.padded_seqs)
        
    def __len__(self):
        return len(self.user_ids)
    
    def __getitem__(self, idx):
        return {
            'user_id': self.user_ids[idx],
            'hist_item_seq': self.padded_seqs[idx],
            'target_item': self.target_items[idx],
            'seq_len': self.seq_lens[idx],
            'label': self.labels[idx]
        }

# åŒå¡”æ¨¡å‹å®šä¹‰
class YouTubeDNNModel(nn.Module):
    def __init__(self, user_count, item_count, embedding_dim=16, hidden_units=(64, 16), dropout=0.2):
        super(YouTubeDNNModel, self).__init__()
        self.embedding_dim = embedding_dim
        
        # ç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥å±‚
        self.user_embedding = nn.Embedding(user_count, embedding_dim)
        self.item_embedding = nn.Embedding(item_count, embedding_dim)
        
        # å†å²ç‰©å“åºåˆ—èšåˆ
        self.hist_embedding = nn.Embedding(item_count, embedding_dim)
        
        # ç”¨æˆ·å¡”æ·±åº¦ç½‘ç»œ
        layers = []
        input_dim = embedding_dim * 2  # ç”¨æˆ·IDåµŒå…¥ + å†å²åºåˆ—åµŒå…¥
        for unit in hidden_units:
            layers.append(nn.Linear(input_dim, unit))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout))
            input_dim = unit
        self.user_dnn = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Embedding):
                nn.init.normal_(m.weight, mean=0.0, std=0.01)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, user_id, hist_item_seq, target_item, seq_len):
        # ç”¨æˆ·ID Embedding
        user_emb = self.user_embedding(user_id)  # [B, E]
        
        # å†å²ç‰©å“åºåˆ—Embedding
        hist_emb = self.hist_embedding(hist_item_seq)  # [B, L, E]
        
        # è®¡ç®—åºåˆ—çš„å¹³å‡å€¼
        device = user_id.device
        mask = torch.arange(hist_item_seq.size(1), device=device).unsqueeze(0) < seq_len.unsqueeze(1)
        mask = mask.unsqueeze(2).float()
        hist_emb = (hist_emb * mask).sum(dim=1) / seq_len.unsqueeze(1).float().clamp(min=1)  # [B, E]
        
        # è¿æ¥ç”¨æˆ·åµŒå…¥å’Œå†å²ç‰©å“åµŒå…¥
        user_feature = torch.cat([user_emb, hist_emb], dim=1)  # [B, 2E]
        
        # ç”¨æˆ·å¡”DNN
        user_dnn_out = self.user_dnn(user_feature)  # [B, last_hidden]
        
        # ç›®æ ‡ç‰©å“Embedding
        item_emb = self.item_embedding(target_item)  # [B, E]
        
        # è®¡ç®—ç‚¹ç§¯
        if len(item_emb.shape) == 3:  # æ‰¹é‡è®¡ç®—å¤šä¸ªç‰©å“ [B, N, E]
            score = torch.bmm(user_dnn_out.unsqueeze(1), item_emb.transpose(1, 2)).squeeze(1)  # [B, N]
        else:  # å•ä¸ªç‰©å“ [B, E]
            score = torch.sum(user_dnn_out * item_emb, dim=1)  # [B]
        
        return score
    
    def get_user_embedding(self, user_id, hist_item_seq, seq_len):
        user_emb = self.user_embedding(user_id)
        hist_emb = self.hist_embedding(hist_item_seq)
        
        device = user_id.device
        mask = torch.arange(hist_item_seq.size(1), device=device).unsqueeze(0) < seq_len.unsqueeze(1)
        mask = mask.unsqueeze(2).float()
        hist_emb = (hist_emb * mask).sum(dim=1) / seq_len.unsqueeze(1).float().clamp(min=1)
        
        user_feature = torch.cat([user_emb, hist_emb], dim=1)
        user_dnn_out = self.user_dnn(user_feature)
        
        return user_dnn_out
    
    def get_item_embedding(self, item_id):
        return self.item_embedding(item_id)


# è·å–åŒå¡”å¬å›æ—¶çš„è®­ç»ƒéªŒè¯æ•°æ®
# negsampleæŒ‡çš„æ˜¯é€šè¿‡æ»‘çª—æ„å»ºæ ·æœ¬çš„æ—¶å€™ï¼Œè´Ÿæ ·æœ¬çš„æ•°é‡
def gen_data_set(data, negsample=0, max_hist_len=30, cache_path=None, use_cache=True):
    """
    ç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œæ”¯æŒç¼“å­˜
    """
    # å¦‚æœå¯ç”¨ç¼“å­˜ä¸”ç¼“å­˜æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥åŠ è½½
    if use_cache and cache_path and os.path.exists(cache_path):
        print(f"âœ… Loaded train/test datasets from cache: {cache_path}")  # ä»ç¼“å­˜åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    
    print("ğŸš€ Generating training and test datasets...")  # å¼€å§‹ç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†...
    data.sort_values("click_timestamp", inplace=True)
    
    # è·å–ç¼–ç åçš„ç‰©å“IDèŒƒå›´
    item_ids = data['click_article_id_encoded'].unique()
    max_item_id = item_ids.max()
    print(f"Encoded item ID range: 0-{max_item_id}")  # ç¼–ç åç‰©å“IDèŒƒå›´
    
    train_set = []
    test_set = []
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
    for reviewerID, hist in tqdm(data.groupby('user_id_encoded'), desc="æ„å»ºè®­ç»ƒæ ·æœ¬"):
        pos_list = hist['click_article_id_encoded'].tolist()
        
        if negsample > 0:
            # ä¿®æ”¹è´Ÿé‡‡æ ·é€»è¾‘ï¼Œç¡®ä¿é‡‡æ ·çš„IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
            valid_item_ids = item_ids[item_ids < max_item_id + 1]
            candidate_set = list(set(valid_item_ids) - set(pos_list))
            
            if len(candidate_set) < negsample:
                # å¦‚æœå€™é€‰é›†å¤ªå°ï¼Œå…è®¸é‡å¤é‡‡æ ·
                neg_list = np.random.choice(candidate_set, size=len(pos_list) * negsample, replace=True)
            else:
                # å¦åˆ™ä¸å…è®¸é‡å¤é‡‡æ ·
                neg_list = np.random.choice(candidate_set, size=len(pos_list) * negsample, replace=False)

        if len(pos_list) == 1:
            train_set.append((reviewerID, [pos_list[0]], pos_list[0], 1, 1))
            test_set.append((reviewerID, [pos_list[0]], pos_list[0], 1, 1))
            continue

        for i in range(1, len(pos_list)):
            hist = pos_list[:i]
            hist = hist[-max_hist_len:] if len(hist) > max_hist_len else hist

            if i != len(pos_list) - 1:
                train_set.append((reviewerID, hist[::-1], pos_list[i], 1, len(hist[::-1])))
                for negi in range(negsample):
                    neg_item = neg_list[i * negsample + negi]
                    train_set.append((reviewerID, hist[::-1], neg_item, 0, len(hist[::-1])))
            else:
                test_set.append((reviewerID, hist[::-1], pos_list[i], 1, len(hist[::-1])))

    # æ‰“ä¹±æ•°æ®
    random.shuffle(train_set)
    random.shuffle(test_set)
    
    # éªŒè¯ç”Ÿæˆçš„æ•°æ®é›†
    print("Validating dataset...")  # éªŒè¯æ•°æ®é›†...
    max_user_id = data['user_id_encoded'].max()
    max_item_id = data['click_article_id_encoded'].max()
    
    for sample in train_set + test_set:
        user_id, hist_items, target_item, label, seq_len = sample
        assert user_id <= max_user_id, f"ç”¨æˆ·ID {user_id} è¶…å‡ºèŒƒå›´ {max_user_id}"
        assert target_item <= max_item_id, f"ç‰©å“ID {target_item} è¶…å‡ºèŒƒå›´ {max_item_id}"
        assert all(item <= max_item_id for item in hist_items), f"å†å²ç‰©å“åˆ—è¡¨åŒ…å«è¶…å‡ºèŒƒå›´çš„ID"
    
    print(f"âœ… Dataset validation passed")  # æ•°æ®é›†éªŒè¯é€šè¿‡
    print(f"Train set size: {len(train_set)}")  # è®­ç»ƒé›†å¤§å°
    print(f"Test set size: {len(test_set)}")  # æµ‹è¯•é›†å¤§å°
    
    # å¦‚æœæŒ‡å®šäº†ç¼“å­˜è·¯å¾„ï¼Œä¿å­˜ç»“æœ
    if cache_path:
        print(f"ğŸ’¾ Saving train/test datasets to cache: {cache_path}")  # ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ°ç¼“å­˜
        os.makedirs(os.path.dirname(cache_path), exist_ok=True)
        with open(cache_path, 'wb') as f:
            pickle.dump((train_set, test_set), f)
    
    return train_set, test_set


def train_youtube_dnn(train_dataloader, test_dataloader, model, device, epochs=5, 
                     learning_rate=0.001, weight_decay=1e-6):
    """
    è®­ç»ƒYouTubeDNNæ¨¡å‹ï¼Œæ·»åŠ é”™è¯¯å¤„ç†å’Œæ•°æ®éªŒè¯
    """
    print(f"[train_youtube_dnn] Starting training, device: {device}")  # å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡
    
    # 1. è®¾ç½®CUDAç¯å¢ƒå˜é‡ï¼Œå¸®åŠ©è°ƒè¯•
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    try:
        # 2. ç¡®ä¿æ¨¡å‹å’Œæ•°æ®åœ¨åŒä¸€è®¾å¤‡ä¸Š
        model = model.to(device)
        
        # 3. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        scaler = torch.cuda.amp.GradScaler()
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.BCEWithLogitsLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        
        # è®°å½•æœ€ä½³éªŒè¯æŸå¤±ï¼Œç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹
        best_val_loss = float('inf')
        best_model_state = None
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            train_batches = 0
            
            for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}')):
                try:
                    # 4. åœ¨ç§»åŠ¨æ•°æ®åˆ°GPUå‰å…ˆéªŒè¯æ•°æ®
                    user_id = batch['user_id'].long()
                    hist_item_seq = batch['hist_item_seq'].long()
                    target_item = batch['target_item'].long()
                    seq_len = batch['seq_len'].long()
                    label = batch['label'].float()
                    
                    # æ‰“å°è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                    if batch_idx == 0:
                        print(f"User ID range: {user_id.min()}-{user_id.max()}, embedding size: {model.user_embedding.num_embeddings}")  # ç”¨æˆ·IDèŒƒå›´/åµŒå…¥å±‚èŒƒå›´
                        print(f"Item ID range: {hist_item_seq.max()}, embedding size: {model.item_embedding.num_embeddings}")  # ç‰©å“IDèŒƒå›´/åµŒå…¥å±‚èŒƒå›´
                    
                    # ä¸¥æ ¼çš„èŒƒå›´æ£€æŸ¥
                    if user_id.max() >= model.user_embedding.num_embeddings:
                        print(f"Warning: user ID {user_id.max()} out of range {model.user_embedding.num_embeddings}")  # è­¦å‘Šï¼šç”¨æˆ·IDè¶…å‡ºèŒƒå›´
                        continue
                    if hist_item_seq.max() >= model.item_embedding.num_embeddings:
                        print(f"Warning: item ID {hist_item_seq.max()} out of range {model.item_embedding.num_embeddings}")  # è­¦å‘Šï¼šç‰©å“IDè¶…å‡ºèŒƒå›´
                        continue
                    
                    # 6. ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                    user_id = user_id.to(device)
                    hist_item_seq = hist_item_seq.to(device)
                    target_item = target_item.to(device)
                    seq_len = seq_len.to(device)
                    label = label.to(device)
                    
                    # 7. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
                    with torch.cuda.amp.autocast():
                        scores = model(user_id, hist_item_seq, target_item, seq_len)
                        loss = criterion(scores, label)
                    
                    optimizer.zero_grad()
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                    
                    train_loss += loss.item()
                    train_batches += 1
                    
                    if (batch_idx + 1) % 100 == 0:
                        avg_train_loss = train_loss / (train_batches + 1)
                        print(f"  Batch {batch_idx+1}/{len(train_dataloader)}, "
                              f"Loss: {loss.item():.4f}, "
                              f"Avg Loss: {avg_train_loss:.4f}")
                        
                except RuntimeError as e:
                    print(f"Training batch {batch_idx} error: {str(e)}")  # è®­ç»ƒæ‰¹æ¬¡å‡ºé”™
                    torch.cuda.empty_cache()
                    continue
            
            # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
            avg_train_loss = train_loss / max(1, train_batches)
            
            # éªŒè¯é˜¶æ®µ
            print(f"\nStarting validation epoch {epoch+1}...")  # å¼€å§‹ç¬¬...è½®éªŒè¯...
            model.eval()
            val_loss = 0.0
            val_batches = 0
            
            with torch.no_grad():
                for batch_idx, batch in enumerate(tqdm(test_dataloader, desc="éªŒè¯")):
                    try:
                        # åœ¨å½“å‰è®¾å¤‡ä¸Šè¿›è¡ŒéªŒè¯
                        user_id = batch['user_id'].long().to(device)
                        hist_item_seq = batch['hist_item_seq'].long().to(device)
                        target_item = batch['target_item'].long().to(device)
                        seq_len = batch['seq_len'].long().to(device)
                        label = batch['label'].float().to(device)
                        
                        scores = model(user_id, hist_item_seq, target_item, seq_len)
                        loss = criterion(scores, label)
                        
                        val_loss += loss.item()
                        val_batches += 1
                        
                        if (batch_idx + 1) % 100 == 0:
                                print(f"  Validation batch {batch_idx+1}/{len(test_dataloader)}, "
                                  f"Loss: {loss.item():.4f}")
                            
                    except Exception as e:
                        print(f"Validation batch {batch_idx} error: {str(e)}")  # éªŒè¯æ‰¹æ¬¡å‡ºé”™
                        continue
            
            # è®¡ç®—å¹³å‡éªŒè¯æŸå¤±
            avg_val_loss = val_loss / max(1, val_batches)
            
            print(f'Epoch {epoch+1}/{epochs}, '
                  f'Train Loss: {avg_train_loss:.4f}, '
                  f'Val Loss: {avg_val_loss:.4f}')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                best_model_state = {k: v.cpu() for k, v in model.state_dict().items()}
                print(f"Found better model, validation loss: {best_val_loss:.4f}")  # å‘ç°æ›´å¥½çš„æ¨¡å‹
        
        # æ¢å¤æœ€ä½³æ¨¡å‹çŠ¶æ€
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
            print(f"Restored best model, validation loss: {best_val_loss:.4f}")  # å·²æ¢å¤æœ€ä½³æ¨¡å‹
        
    except Exception as e:
        print(f"Training process error: {str(e)}")  # è®­ç»ƒè¿‡ç¨‹å‘ç”Ÿé”™è¯¯
        raise  # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿æŸ¥çœ‹å®Œæ•´çš„é”™è¯¯å †æ ˆ
        
    print("[train_youtube_dnn] Training completed!")  # è®­ç»ƒå®Œæˆ
    return model


def youtubednn_u2i_dict(data, save_path="./cache/", topk=20, epochs=5, batch_size=256, embedding_dim=32):
    # å®šä¹‰æ‰€æœ‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
    model_cache = os.path.join(save_path, 'youtube_model.pth')
    embeddings_cache = os.path.join(save_path, 'youtube_embeddings.pkl')
    cache_path = os.path.join(save_path, 'youtube_u2i_dict.pkl')
    dataset_cache = os.path.join(save_path, 'youtube_dataset.pkl')
    
    print("[youtubednn_u2i_dict] ğŸš€ Starting YouTubeDNN processing...")  # å¼€å§‹YouTubeDNNå¤„ç†...
    
    # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
    os.makedirs(save_path, exist_ok=True)
    
    # 1. ä¿®æ”¹IDç¼–ç éƒ¨åˆ†
    print("[youtubednn_u2i_dict] Starting ID encoding...")  # å¼€å§‹IDç¼–ç ...
    user_encoder = LabelEncoder()
    item_encoder = LabelEncoder()
    
    # è·å–æ‰€æœ‰å¯èƒ½çš„ç‰©å“ID
    all_item_ids = data['click_article_id'].unique()
    max_item_id = max(all_item_ids)
    print(f"[youtubednn_u2i_dict] Raw item ID range: 0-{max_item_id}")  # åŸå§‹ç‰©å“IDèŒƒå›´
    
    # ç¡®ä¿IDä»0å¼€å§‹è¿ç»­
    data['user_id_encoded'] = user_encoder.fit_transform(data['user_id'])
    data['click_article_id_encoded'] = item_encoder.fit_transform(data['click_article_id'])
    
    # è·å–ç¼–ç åçš„ç”¨æˆ·å’Œç‰©å“æ•°é‡ï¼Œå¹¶æ·»åŠ ä¸€äº›ä½™é‡
    user_count = len(user_encoder.classes_) + 1  # +1 for padding
    item_count = len(item_encoder.classes_) + 1  # +1 for padding
    
    # éªŒè¯ç¼–ç ç»“æœ
    max_encoded_item = data['click_article_id_encoded'].max()
    print(f"[youtubednn_u2i_dict] Encoded counts - users: {user_count}, items: {item_count}")  # ç¼–ç åç”¨æˆ·æ•°é‡/ç‰©å“æ•°é‡
    print(f"[youtubednn_u2i_dict] Max encoded item ID: {max_encoded_item}")  # ç¼–ç åç‰©å“IDæœ€å¤§å€¼
    
    # åˆ›å»ºIDæ˜ å°„å­—å…¸ä»¥ä¾¿è°ƒè¯•
    id_mapping = dict(zip(item_encoder.classes_, item_encoder.transform(item_encoder.classes_)))
    
    # éªŒè¯æ‰€æœ‰ç‰©å“IDéƒ½åœ¨æ­£ç¡®èŒƒå›´å†…
    invalid_ids = data[data['click_article_id_encoded'] >= item_count]['click_article_id'].unique()
    if len(invalid_ids) > 0:
        print(f"[Warning] Found {len(invalid_ids)} item IDs out of range")  # å‘ç°è¶…å‡ºèŒƒå›´çš„ç‰©å“ID
        print(f"Samples: {invalid_ids[:5]}")  # æ ·ä¾‹
        
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ - ä½¿ç”¨éªŒè¯åçš„item_count
    model = YouTubeDNNModel(
        user_count, 
        item_count,  # ç¡®ä¿è¿™ä¸ªæ•°å€¼è¶³å¤Ÿå¤§
        embedding_dim=embedding_dim,
        hidden_units=(128, 64, embedding_dim),
        dropout=0.3
    )
    
    # 2. æ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„è®­ç»ƒæ¨¡å‹
    if os.path.exists(model_cache):
        print(f"[youtubednn_u2i_dict] âœ… Loaded pretrained model: {model_cache}")  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model.load_state_dict(torch.load(model_cache))
    else:
        # å¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡Œè®­ç»ƒ
        train_set, test_set = gen_data_set(
            data,  # è¿™é‡Œä¼ å…¥çš„dataå·²ç»åŒ…å«äº†ç¼–ç åçš„ID
            negsample=4, 
            max_hist_len=30,
            cache_path=dataset_cache,
            use_cache=True
        )
        
        # 3. åˆ›å»ºæ•°æ®é›†æ—¶ä½¿ç”¨ç¼–ç åçš„ID
        train_dataset = YouTubeDNNDataset(
            user_ids=[x[0] for x in train_set],  # è¿™é‡Œå·²ç»æ˜¯ç¼–ç åçš„user_id
            item_seqs=[x[1] for x in train_set],  # è¿™é‡Œæ˜¯ç¼–ç åçš„itemåºåˆ—
            target_items=[x[2] for x in train_set],  # è¿™é‡Œæ˜¯ç¼–ç åçš„target_item
            labels=[x[3] for x in train_set],
            seq_lens=[x[4] for x in train_set]
        )
        
        test_dataset = YouTubeDNNDataset(
            user_ids=[x[0] for x in test_set],
            item_seqs=[x[1] for x in test_set],
            target_items=[x[2] for x in test_set],
            labels=[x[3] for x in test_set],
            seq_lens=[x[4] for x in test_set]
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataloader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=4
        )
        
        test_dataloader = DataLoader(
            test_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=4
        )
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # è®­ç»ƒæ¨¡å‹
        model = train_youtube_dnn(
            train_dataloader=train_dataloader,
            test_dataloader=test_dataloader,
            model=model,
            device=device,
            epochs=epochs,
            learning_rate=0.001,
            weight_decay=1e-6
        )
        
        # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        torch.save(model.state_dict(), model_cache)
    
    # åˆå§‹åŒ–åµŒå…¥å˜é‡
    user_embeddings = {}
    item_embeddings = {}
    
    if os.path.exists(embeddings_cache):
        print(f"[youtubednn_u2i_dict] âœ… Found embedding cache: {embeddings_cache}")  # å‘ç°åµŒå…¥ç¼“å­˜
        with open(embeddings_cache, 'rb') as f:
            cache_data = pickle.load(f)
            user_embeddings = cache_data['user_embeddings']
            item_embeddings = cache_data['item_embeddings']
    else:
        print("[youtubednn_u2i_dict] âš ï¸ Embedding cache not found, recomputing embeddings")  # æœªæ‰¾åˆ°åµŒå…¥ç¼“å­˜ï¼Œå°†é‡æ–°è®¡ç®—åµŒå…¥
        # è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[youtubednn_u2i_dict] Using device: {device}")  # ä½¿ç”¨è®¾å¤‡

        # å°†æ¨¡å‹ç§»åˆ°æ­£ç¡®çš„è®¾å¤‡ä¸Š
        model = model.to(device)
        model.eval()

        with torch.no_grad():
            # ä¸ºæ‰€æœ‰ç‰©å“è®¡ç®—åµŒå…¥
            encoded_items = torch.LongTensor(range(item_count)).to(device)  # ç§»åŠ¨åˆ°åŒä¸€è®¾å¤‡
            item_embs = model.get_item_embedding(encoded_items).detach().cpu().numpy()
            
            # ä¿å­˜æ—¶ä½¿ç”¨åŸå§‹ID
            for idx, orig_item_id in enumerate(item_encoder.classes_):
                item_embeddings[orig_item_id] = item_embs[idx]
            
            # ä¸ºæ‰€æœ‰ç”¨æˆ·è®¡ç®—åµŒå…¥
            for user_id in tqdm(data['user_id'].unique(), desc="Computing user embeddings"):
                # è·å–ç”¨æˆ·çš„å†å²äº¤äº’
                user_hist = data[data['user_id'] == user_id]['click_article_id_encoded'].tolist()
                if not user_hist:
                    continue
                
                # å‡†å¤‡æ¨¡å‹è¾“å…¥
                encoded_user_id = user_encoder.transform([user_id])[0]
                hist_items = user_hist[-30:]  # æœ€å¤šä½¿ç”¨æœ€è¿‘30ä¸ªäº¤äº’
                hist_len = len(hist_items)
                hist_tensor = torch.LongTensor(hist_items + [0] * (30 - hist_len)).to(device)  # ç§»åŠ¨åˆ°åŒä¸€è®¾å¤‡
                hist_tensor = hist_tensor.unsqueeze(0)
                user_tensor = torch.LongTensor([encoded_user_id]).to(device)  # ç§»åŠ¨åˆ°åŒä¸€è®¾å¤‡
                seq_len = torch.LongTensor([hist_len]).to(device)  # ç§»åŠ¨åˆ°åŒä¸€è®¾å¤‡
                
                # è·å–ç”¨æˆ·åµŒå…¥
                try:
                    user_emb = model.get_user_embedding(user_tensor, hist_tensor, seq_len).cpu().numpy()  # å…ˆè½¬åˆ°CPU
                    user_embeddings[user_id] = user_emb.squeeze() / np.linalg.norm(user_emb)
                except Exception as e:
                    print(f"[youtubednn_u2i_dict] âš ï¸ Error processing embedding for user {user_id}: {str(e)}")  # å¤„ç†ç”¨æˆ·åµŒå…¥æ—¶å‡ºé”™
                    continue
        
        # ä¿å­˜åµŒå…¥
        cache_data = {
            'user_embeddings': user_embeddings,
            'item_embeddings': item_embeddings,
            'user_encoder': user_encoder,
            'item_encoder': item_encoder
        }
        with open(embeddings_cache, 'wb') as f:
            pickle.dump(cache_data, f)
    
    # ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢
    print("[youtubednn_u2i_dict] Using Faiss for vector retrieval...")  # ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢...
    user_ids = list(user_embeddings.keys())  # ä½¿ç”¨user_embeddingsè€Œä¸æ˜¯user_embs
    user_embs = np.array([user_embeddings[user_id] for user_id in user_ids], dtype=np.float32)
    
    item_ids = list(item_embeddings.keys())  # ä½¿ç”¨item_embeddingsè€Œä¸æ˜¯item_embs
    item_embs = np.array([item_embeddings[item_id] for item_id in item_ids], dtype=np.float32)
    
    # æ„å»ºç´¢å¼•
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(item_embs)
    
    # æœç´¢æœ€ç›¸ä¼¼çš„ç‰©å“
    sim, idx = index.search(user_embs, topk)
    
    # ç”Ÿæˆå¬å›ç»“æœ
    user_recall_items_dict = {}
    for i, user_id in enumerate(user_ids):
        item_list = []
        for j, item_idx in enumerate(idx[i]):
            if item_idx < len(item_ids):  # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
                item_id = item_ids[item_idx]
                score = sim[i][j]
                item_list.append((item_id, float(score)))
        user_recall_items_dict[user_id] = item_list
    
    # ä¿å­˜å¬å›ç»“æœ
    with open(cache_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)
    
    print(f"[youtubednn_u2i_dict] âœ… Recall results saved to: {cache_path}")  # å¬å›ç»“æœå·²ä¿å­˜è‡³
    
    # ä¿®æ”¹æ£€æŸ¥ä»£ç éƒ¨åˆ†
    print("[youtubednn_u2i_dict] Checking embedding quality...")  # æ£€æŸ¥åµŒå…¥è´¨é‡...
    with torch.no_grad():
        # æŠ½æ ·æ£€æŸ¥ä¸€äº›ç”¨æˆ·åµŒå…¥å’Œç‰©å“åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦
        # ä»å­—å…¸ä¸­æŠ½æ ·ï¼Œè€Œä¸æ˜¯ä»numpyæ•°ç»„ä¸­æŠ½æ ·
        user_sample = list(user_embeddings.items())[:3]
        item_sample = list(item_embeddings.items())[:5]
        
        print("Sample user embeddings:")  # æ ·æœ¬ç”¨æˆ·åµŒå…¥
        for u_id, u_emb in user_sample:
            print(f"User ID: {u_id}, embedding norm: {np.linalg.norm(u_emb)}")  # ç”¨æˆ·ID/åµŒå…¥èŒƒæ•°
            
            # æ£€æŸ¥ä¸æ ·æœ¬ç‰©å“çš„ç›¸ä¼¼åº¦
            for i_id, i_emb in item_sample:
                sim = np.dot(u_emb, i_emb) / (np.linalg.norm(u_emb) * np.linalg.norm(i_emb))
                print(f"  Similarity to item {i_id}: {sim:.4f}")  # ä¸ç‰©å“...çš„ç›¸ä¼¼åº¦
    
    return user_recall_items_dict 

def get_youtube_recall(train_df, val_df, save_path, use_cache=True, epochs=10, 
                      batch_size=32,  # å‡å°batch_size
                      embedding_dim=32):
    """
    ä½¿ç”¨PyTorchç‰ˆæœ¬çš„YouTubeDNNæ¨¡å‹ç”Ÿæˆç”¨æˆ·-ç‰©å“å¬å›è¡¨
    
    Args:
        train_df: è®­ç»ƒæ•°æ®
        val_df: éªŒè¯æ•°æ®
        save_path: ç»“æœä¿å­˜è·¯å¾„
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹å¤§å°
        embedding_dim: åµŒå…¥ç»´åº¦
        
    Returns:
        ç”¨æˆ·-ç‰©å“å¬å›è¡¨ï¼Œæ ¼å¼ä¸º{ç”¨æˆ·ID: [(ç‰©å“ID, å¾—åˆ†), ...]}
    """
    # å®šä¹‰ç›¸å…³ç¼“å­˜è·¯å¾„
    cache_path = os.path.join(save_path, 'youtube_u2i_dict.pkl')
    model_path = os.path.join(save_path, 'youtube_dnn_model.pth')
    user_emb_path = os.path.join(save_path, 'user_youtube_emb.pkl') 
    item_emb_path = os.path.join(save_path, 'item_youtube_emb.pkl')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(save_path, exist_ok=True)
    
    # æ£€æŸ¥å¬å›ç»“æœç¼“å­˜
    if use_cache and os.path.exists(cache_path):
        print(f"[get_youtube_recall] âœ… Using cache: {cache_path}")  # ä½¿ç”¨ç¼“å­˜
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    
    print("[get_youtube_recall] ğŸš€ Generating YouTubeDNN recall results...")  # ç”ŸæˆYouTubeDNNå¬å›ç»“æœ...
    
    # ç¡®ä¿æ‰€æœ‰IDéƒ½ç»è¿‡ç¼–ç 
    item_encoder = LabelEncoder()
    user_encoder = LabelEncoder()
    
    # å…ˆå¯¹æ‰€æœ‰å¯èƒ½çš„IDè¿›è¡Œfit
    all_item_ids = pd.concat([train_df['click_article_id'], val_df['click_article_id']]).unique()
    all_user_ids = pd.concat([train_df['user_id'], val_df['user_id']]).unique()
    
    item_encoder.fit(all_item_ids)
    user_encoder.fit(all_user_ids)
    
    # ç„¶åå†transform
    train_df['click_article_id_encoded'] = item_encoder.transform(train_df['click_article_id'])
    val_df['click_article_id_encoded'] = item_encoder.transform(val_df['click_article_id'])
    
    # ä»…ä½¿ç”¨ç”¨æˆ·å’Œç‰©å“IDï¼Œç®€åŒ–å¤„ç†
    df = pd.concat([train_df, val_df], ignore_index=True)
    user_count = df['user_id'].nunique() + 1  # +1 é¿å…ç´¢å¼•è¶Šç•Œ
    item_count = df['click_article_id'].nunique() + 1  # +1 é¿å…ç´¢å¼•è¶Šç•Œ
    
    # è·å–æ‰€æœ‰å”¯ä¸€ç”¨æˆ·å’Œç‰©å“ID
    unique_users = df['user_id'].unique()
    unique_items = df['click_article_id'].unique()
    
    # è·å–ç”¨æˆ·å†å²äº¤äº’
    user_hist_dict = {}
    for user_id, group in df.groupby('user_id'):
        user_hist_dict[user_id] = group.sort_values('click_timestamp')['click_article_id'].tolist()
    
    # åˆ›å»ºæ¨¡å‹æ—¶ä½¿ç”¨è¾ƒå°çš„éšè—å±‚
    model = YouTubeDNNModel(
        user_count, 
        item_count, 
        embedding_dim=embedding_dim,
        hidden_units=(64, 32),  # å‡å°éšè—å±‚
        dropout=0.2
    )
    
    # æ£€æŸ¥æ¨¡å‹ç¼“å­˜
    if use_cache and os.path.exists(model_path):
        print(f"[get_youtube_recall] âœ… Loaded pretrained model: {model_path}")  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model.load_state_dict(torch.load(model_path))
    
    # æ£€æŸ¥åµŒå…¥ç¼“å­˜
    if use_cache and os.path.exists(user_emb_path) and os.path.exists(item_emb_path):
        print(f"[get_youtube_recall] âœ… Loaded user and item embeddings")  # åŠ è½½ç”¨æˆ·å’Œç‰©å“åµŒå…¥
        with open(user_emb_path, 'rb') as f:
            user_embeddings = pickle.load(f)
        with open(item_emb_path, 'rb') as f:
            item_embeddings = pickle.load(f)
    else:
        # ç”Ÿæˆç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥
        print("[get_youtube_recall] Computing user and item embeddings...")  # è®¡ç®—ç”¨æˆ·å’Œç‰©å“åµŒå…¥...
        model.eval()
        
        # ä¸ºæ‰€æœ‰ç‰©å“ç”ŸæˆåµŒå…¥
        with torch.no_grad():
            all_item_ids = torch.LongTensor(unique_items)
            all_item_embs = model.get_item_embedding(all_item_ids).detach().numpy()
            normalized_item_embs = all_item_embs / np.linalg.norm(all_item_embs, axis=1, keepdims=True)
            
            # ä¿å­˜ç‰©å“åµŒå…¥å­—å…¸
            item_embeddings = {item_id: emb for item_id, emb in zip(unique_items, normalized_item_embs)}
            with open(item_emb_path, 'wb') as f:
                pickle.dump(item_embeddings, f)
        
        # è®¡ç®—ç”¨æˆ·åµŒå…¥
        user_embeddings = {}
        max_seq_len = 30
        
        with torch.no_grad():
            for user_id in tqdm(unique_users, desc="Computing user embeddings"):
                if user_id not in user_hist_dict or len(user_hist_dict[user_id]) == 0:
                    continue
                    
                # è·å–å†å²äº¤äº’ï¼Œç¡®ä¿å†…å®¹åœ¨item_countèŒƒå›´å†…
                hist_items = [i for i in user_hist_dict[user_id] if i < item_count]
                if not hist_items:
                    continue
                    
                # æœ€å¤šä½¿ç”¨æœ€è¿‘30ä¸ªäº¤äº’
                hist_items = hist_items[-max_seq_len:] if len(hist_items) > max_seq_len else hist_items
                hist_len = len(hist_items)
                
                # å°†å†å²äº¤äº’è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥ï¼Œç¡®ä¿paddingæ­£ç¡®
                hist_tensor = torch.LongTensor(hist_items + [0] * (max_seq_len - hist_len))
                hist_tensor = hist_tensor.unsqueeze(0)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦
                user_tensor = torch.LongTensor([user_id])
                seq_len = torch.LongTensor([hist_len])
                
                # è·å–ç”¨æˆ·åµŒå…¥
                try:
                    user_emb = model.get_user_embedding(user_tensor, hist_tensor, seq_len).numpy()
                    user_embeddings[user_id] = user_emb.squeeze() / np.linalg.norm(user_emb)
                except Exception as e:
                    print(f"[get_youtube_recall] âš ï¸ Error processing embedding for user {user_id}: {str(e)}")  # å¤„ç†ç”¨æˆ·åµŒå…¥æ—¶å‡ºé”™
                    continue
        
        # ä¿å­˜ç”¨æˆ·åµŒå…¥
        with open(user_emb_path, 'wb') as f:
            pickle.dump(user_embeddings, f)
    
    # å‡†å¤‡å‘é‡æ£€ç´¢
    print("[get_youtube_recall] Using Faiss for vector retrieval...")  # ä½¿ç”¨Faissè¿›è¡Œå‘é‡æ£€ç´¢...
    user_ids = list(user_embeddings.keys())
    user_embs = np.array([user_embeddings[user_id] for user_id in user_ids], dtype=np.float32)
    
    item_ids = list(item_embeddings.keys())
    item_embs = np.array([item_embeddings[item_id] for item_id in item_ids], dtype=np.float32)
    
    # æ„å»ºç´¢å¼•
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(np.ascontiguousarray(item_embs))
    
    # ä¸ºéªŒè¯é›†ä¸­çš„ç”¨æˆ·ç”Ÿæˆå¬å›ç»“æœ
    user_recall_items_dict = {}
    topk = recall_num  # æ¯ä¸ªç”¨æˆ·å¬å›æŒ‡å®šæ•°é‡çš„æ–‡ç« 
    
    # æ‰§è¡Œå‘é‡æ£€ç´¢
    sim, idx = index.search(np.ascontiguousarray(user_embs), topk)
    
    # æ„å»ºç”¨æˆ·å¬å›ç»“æœ
    for i, user_id in enumerate(user_ids):
        item_list = []
        for j, item_idx in enumerate(idx[i]):
            if item_idx < len(item_ids):
                item_id = item_ids[item_idx]
                score = float(sim[i][j])
                item_list.append((item_id, score))
        user_recall_items_dict[user_id] = item_list
    
    # ä¿å­˜å¬å›ç»“æœ
    with open(cache_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)
    
    print(f"[get_youtube_recall] âœ… Recall results saved to: {cache_path}")  # å¬å›ç»“æœå·²ä¿å­˜è‡³
    return user_recall_items_dict 