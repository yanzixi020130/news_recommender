import math
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import pickle
import os

from utils import get_user_item_time_dict

def itemcf_sim(df, item_created_time_dict, save_path, use_cache=True):
    """
        æ–‡ç« ä¸æ–‡ç« ä¹‹é—´çš„ç›¸ä¼¼æ€§çŸ©é˜µè®¡ç®—
        :param df: æ•°æ®è¡¨
        :item_created_time_dict:  æ–‡ç« åˆ›å»ºæ—¶é—´çš„å­—å…¸
        return : æ–‡ç« ä¸æ–‡ç« çš„ç›¸ä¼¼æ€§çŸ©é˜µ
        æ€è·¯: åŸºäºç‰©å“çš„ååŒè¿‡æ»¤(è¯¦ç»†è¯·å‚è€ƒä¸Šä¸€æœŸæ¨èç³»ç»ŸåŸºç¡€çš„ç»„é˜Ÿå­¦ä¹ )ï¼Œ åœ¨å¤šè·¯å¬å›éƒ¨åˆ†ä¼šåŠ ä¸Šå…³è”è§„åˆ™çš„å¬å›ç­–ç•¥
        å¯è‡ªåŠ¨ç¼“å­˜å’Œå¤ç”¨å·²æœ‰ç»“æœ
    """
    # å¦‚æœæ˜¯ç›®å½•è·¯å¾„ï¼Œå°±æ‹¼æ¥é»˜è®¤æ–‡ä»¶å
    if os.path.splitext(save_path)[1] == '':
        # æ²¡æœ‰æ‰©å±•åï¼Œè¯´æ˜æ˜¯ç›®å½•
        save_path = os.path.join(save_path, 'itemcf_i2i_sim.pkl')

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    # ç¼“å­˜åˆ¤æ–­
    if use_cache and os.path.exists(save_path):
        print(f"[itemcf_sim] âœ… Using cached file: {save_path}")  # ä½¿ç”¨ç¼“å­˜æ–‡ä»¶
        with open(save_path, 'rb') as f:
            return pickle.load(f)

    # å¦åˆ™é‡æ–°è®¡ç®—
    print(f"[itemcf_sim] Recomputing similarity matrix...")  # é‡æ–°è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ...

    user_item_time_dict = get_user_item_time_dict(df)

    # è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦
    i2i_sim = {}
    item_cnt = defaultdict(int)
    for user, item_time_list in tqdm(user_item_time_dict.items()):
        # åœ¨åŸºäºå•†å“çš„ååŒè¿‡æ»¤ä¼˜åŒ–çš„æ—¶å€™å¯ä»¥è€ƒè™‘æ—¶é—´å› ç´ 
        # åœ¨åŸºäºå•†å“çš„ååŒè¿‡æ»¤ä¼˜åŒ–çš„æ—¶å€™å¯ä»¥è€ƒè™‘æ—¶é—´å› ç´ 
        for loc1, (i, i_click_time) in enumerate(item_time_list):
            item_cnt[i] += 1
            i2i_sim.setdefault(i, {})
            for loc2, (j, j_click_time) in enumerate(item_time_list):
                if i == j:
                    continue
                # æ­£å‘/åå‘ç‚¹å‡»é¡ºåºåŒºåˆ†ï¼ˆä½ç½®å…³ç³»ï¼‰
                loc_alpha = 1.0 if loc2 > loc1 else 0.7
                # ä½ç½®æƒé‡ï¼ˆç‚¹å‡»é¡ºåºè¶Šè¿‘ï¼Œè¶Šç›¸å…³ï¼‰å…¶ä¸­çš„å‚æ•°å¯ä»¥è°ƒèŠ‚
                loc_weight = loc_alpha * (0.9 ** (np.abs(loc2 - loc1) - 1))
                # ç‚¹å‡»æ—¶é—´ç›¸è¿‘æƒé‡ï¼ˆå¯ç†è§£ä¸º session å†…æ›´ç›¸å…³ï¼‰å…¶ä¸­çš„å‚æ•°å¯ä»¥è°ƒèŠ‚
                click_time_weight = np.exp(0.7 ** np.abs(i_click_time - j_click_time))
                # æ–‡ç« å‘å¸ƒæ—¶é—´ç›¸è¿‘æƒé‡ï¼ˆé˜²æ­¢è·¨å¹´ä»£æ¨èï¼‰å…¶ä¸­çš„å‚æ•°å¯ä»¥è°ƒèŠ‚
                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))

                i2i_sim[i].setdefault(j, 0)
                # è€ƒè™‘å¤šç§å› ç´ çš„æƒé‡è®¡ç®—æœ€ç»ˆçš„æ–‡ç« ä¹‹é—´çš„ç›¸ä¼¼åº¦
                i2i_sim[i][j] += loc_weight * click_time_weight * created_time_weight / math.log(
                    len(item_time_list) + 1)

    i2i_sim_ = i2i_sim.copy()
    for i, related_items in i2i_sim.items():
        for j, wij in related_items.items():
            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])

    # å°†å¾—åˆ°çš„ç›¸ä¼¼æ€§çŸ©é˜µä¿å­˜åˆ°æœ¬åœ°
    with open(save_path, 'wb') as f:
        pickle.dump(i2i_sim_, f)
    print(f"[itemcf_sim] Similarity matrix saved to: {save_path}")  # ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜è‡³

    return i2i_sim_


# åŸºäºå•†å“çš„å¬å›i2i
def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click,
                         item_created_time_dict, emb_i2i_sim):
    """
        åŸºäºæ–‡ç« ååŒè¿‡æ»¤çš„å¬å›
        :param user_id: ç”¨æˆ·id
        :param user_item_time_dict: å­—å…¸, æ ¹æ®ç‚¹å‡»æ—¶é—´è·å–ç”¨æˆ·çš„ç‚¹å‡»æ–‡ç« åºåˆ—   {user1: {item1: time1, item2: time2..}...}
        :param i2i_sim: å­—å…¸ï¼Œæ–‡ç« ç›¸ä¼¼æ€§çŸ©é˜µ
        :param sim_item_topk: æ•´æ•°ï¼Œ é€‰æ‹©ä¸å½“å‰æ–‡ç« æœ€ç›¸ä¼¼çš„å‰kç¯‡æ–‡ç« 
        :param recall_item_num: æ•´æ•°ï¼Œ æœ€åçš„å¬å›æ–‡ç« æ•°é‡
        :param item_topk_click: åˆ—è¡¨ï¼Œç‚¹å‡»æ¬¡æ•°æœ€å¤šçš„æ–‡ç« åˆ—è¡¨ï¼Œç”¨æˆ·å¬å›è¡¥å…¨
        :param emb_i2i_sim: å­—å…¸åŸºäºå†…å®¹embeddingç®—çš„æ–‡ç« ç›¸ä¼¼çŸ©é˜µ

        return: å¬å›çš„æ–‡ç« åˆ—è¡¨ {item1:score1, item2: score2...}

    """
    # è·å–ç”¨æˆ·å†å²äº¤äº’çš„æ–‡ç« 
    user_hist_items = user_item_time_dict[user_id]
    
    # æå–ç”¨æˆ·å†å²äº¤äº’çš„ç‰©å“IDï¼Œè½¬ä¸ºé›†åˆä»¥åŠ é€ŸæŸ¥æ‰¾
    hist_item_ids = set([x[0] for x in user_hist_items])

    item_rank = {}
    for loc, (i, click_time) in enumerate(user_hist_items):
        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:
            # æ£€æŸ¥jæ˜¯å¦åœ¨ç”¨æˆ·å†å²äº¤äº’ç‰©å“ä¸­
            if j in hist_item_ids:
                continue

            # æ–‡ç« åˆ›å»ºæ—¶é—´å·®æƒé‡
            created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))
            # ç›¸ä¼¼æ–‡ç« å’Œå†å²ç‚¹å‡»æ–‡ç« åºåˆ—ä¸­å†å²æ–‡ç« æ‰€åœ¨çš„ä½ç½®æƒé‡
            loc_weight = (0.9 ** (len(user_hist_items) - loc))

            content_weight = 1.0
            if emb_i2i_sim.get(i, {}).get(j, None) is not None:
                content_weight += emb_i2i_sim[i][j]
            if emb_i2i_sim.get(j, {}).get(i, None) is not None:
                content_weight += emb_i2i_sim[j][i]

            item_rank.setdefault(j, 0)
            item_rank[j] += created_time_weight * loc_weight * content_weight * wij

    # ä¸è¶³10ä¸ªï¼Œç”¨çƒ­é—¨å•†å“è¡¥å…¨
    if len(item_rank) < recall_item_num:
        for i, item in enumerate(item_topk_click):
            if item in item_rank:  # å¡«å……çš„itemåº”è¯¥ä¸åœ¨åŸæ¥çš„åˆ—è¡¨ä¸­
                continue
            item_rank[item] = - i - 100  # éšä¾¿ç»™ä¸ªè´Ÿæ•°å°±è¡Œ
            if len(item_rank) == recall_item_num:
                break

    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]

    return item_rank

# ä½¿ç”¨åŸå§‹ itemcf çŸ©é˜µ + emb æƒé‡èåˆï¼›
def generate_itemcf_recall_dict(val_df,
                                     user_item_time_dict,
                                     i2i_sim,
                                     sim_item_topk,
                                     recall_item_num,
                                     item_topk_click,
                                     item_created_time_dict,
                                     emb_i2i_sim=None,
                                     save_path='cache/user_recall_itemcf.pkl',
                                     use_cache=True):
    """
    åŸºäº ItemCFï¼ˆå¸¦ Emb æƒé‡èåˆï¼‰çš„å¬å›åˆ—è¡¨ç”Ÿæˆ
    """
    if os.path.splitext(save_path)[1] == '':
        save_path = os.path.join(save_path, 'user_recall_itemcf.pkl')

    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    if use_cache and os.path.exists(save_path):
        print(f"[generate_user_recall_dict_itemcf] âœ… Using cache: {save_path}")  # ä½¿ç”¨ç¼“å­˜
        with open(save_path, 'rb') as f:
            return pickle.load(f)

    print("[generate_user_recall_dict_itemcf] ğŸš€ Generating ItemCF recall list...")  # æ­£åœ¨ç”Ÿæˆ ItemCF å¬å›åˆ—è¡¨...
    user_recall_items_dict = {}
    for user in tqdm(val_df['user_id'].unique()):
        rec_items = item_based_recommend(
            user,
            user_item_time_dict,
            i2i_sim,
            sim_item_topk,
            recall_item_num,
            item_topk_click,
            item_created_time_dict,
            emb_i2i_sim
        )
        user_recall_items_dict[user] = rec_items

    with open(save_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)

    print(f"[generate_user_recall_dict_itemcf] âœ… Recall list saved: {save_path}")  # å¬å›åˆ—è¡¨ä¿å­˜æˆåŠŸ
    return user_recall_items_dict

# ä»…ä½¿ç”¨ embedding ç›¸ä¼¼åº¦ä½œä¸ºå¬å›é€šé“
def generate_itemcf_embedding_recall_dict(val_df,
                                         emb_i2i_sim,
                                         user_item_time_dict,
                                         sim_item_topk,
                                         recall_item_num,
                                         item_topk_click,
                                         item_created_time_dict=None,
                                         save_path='cache/user_recall_embedding.pkl',
                                         use_cache=True):
    """
    åŸºäº Embedding ç›¸ä¼¼åº¦çš„å¬å›åˆ—è¡¨ç”Ÿæˆ
    """
    if os.path.splitext(save_path)[1] == '':
        save_path = os.path.join(save_path, 'user_recall_embedding.pkl')

    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    if use_cache and os.path.exists(save_path):
        print(f"[generate_user_recall_dict_embedding] âœ… Using cache: {save_path}")  # ä½¿ç”¨ç¼“å­˜
        with open(save_path, 'rb') as f:
            return pickle.load(f)

    print("[generate_user_recall_dict_embedding] ğŸš€ Generating embedding recall list...")  # æ­£åœ¨ç”Ÿæˆ Embedding å¬å›åˆ—è¡¨...
    user_recall_items_dict = {}
    for user in tqdm(val_df['user_id'].unique()):
        rec_items = item_based_recommend(
            user,
            user_item_time_dict,
            emb_i2i_sim,
            sim_item_topk,
            recall_item_num,
            item_topk_click,
            item_created_time_dict,
            emb_i2i_sim  # æ³¨æ„è¿™é‡Œä¼ å…¥è‡ªèº«å³å¯ï¼Œä¸å½±å“æ¨èå‡½æ•°ä¸­ä½¿ç”¨æƒé‡é€»è¾‘
        )
        user_recall_items_dict[user] = rec_items

    with open(save_path, 'wb') as f:
        pickle.dump(user_recall_items_dict, f)

    print(f"[generate_user_recall_dict_embedding] âœ… Recall list saved: {save_path}")  # å¬å›åˆ—è¡¨ä¿å­˜æˆåŠŸ
    return user_recall_items_dict





