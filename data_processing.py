import numpy as np
import pandas as pd
import pickle
import os
import faiss
import collections
from tqdm import tqdm

# debugæ¨¡å¼ï¼šä»è®­ç»ƒé›†ä¸­åˆ’å‡ºä¸€éƒ¨åˆ†æ•°æ®æ¥è°ƒè¯•ä»£ç 
def get_all_click_sample(data_path='./data_raw/', sample_nums=10000):
    """
        è®­ç»ƒé›†ä¸­é‡‡æ ·ä¸€éƒ¨åˆ†æ•°æ®è°ƒè¯•
        data_path: åŸæ•°æ®çš„å­˜å‚¨è·¯å¾„
        sample_nums: é‡‡æ ·æ•°ç›®ï¼ˆè¿™é‡Œç”±äºæœºå™¨çš„å†…å­˜é™åˆ¶ï¼Œå¯ä»¥é‡‡æ ·ç”¨æˆ·åšï¼‰
    """
    all_click = pd.read_csv(data_path + 'train_click_log.csv')
    all_user_ids = all_click.user_id.unique()

    np.random.seed(42)

    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False)
    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]

    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))
    return all_click


# è¯»å–ç‚¹å‡»æ•°æ®ï¼Œè¿™é‡Œåˆ†æˆçº¿ä¸Šå’Œçº¿ä¸‹ï¼Œå¦‚æœæ˜¯ä¸ºäº†è·å–çº¿ä¸Šæäº¤ç»“æœåº”è¯¥è®²æµ‹è¯•é›†ä¸­çš„ç‚¹å‡»æ•°æ®åˆå¹¶åˆ°æ€»çš„æ•°æ®ä¸­
# å¦‚æœæ˜¯ä¸ºäº†çº¿ä¸‹éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§æˆ–è€…ç‰¹å¾çš„æœ‰æ•ˆæ€§ï¼Œå¯ä»¥åªä½¿ç”¨è®­ç»ƒé›†
def get_all_click_df(data_path='./data_raw/', offline=True):
    if offline:
        all_click = pd.read_csv(data_path + 'train_click_log.csv')
    else:
        trn_click = pd.read_csv(data_path + 'train_click_log.csv')
        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')

        all_click = pd.concat([trn_click, tst_click], ignore_index=True)

    #å»é™¤å®Œå…¨é‡å¤çš„æ•°æ®
    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))
    return all_click


# è¯»å–æ–‡ç« çš„åŸºæœ¬å±æ€§
def get_item_info_df(data_path):
    item_info_df = pd.read_csv(data_path + 'articles.csv')

    # ä¸ºäº†æ–¹ä¾¿ä¸è®­ç»ƒé›†ä¸­çš„click_article_idæ‹¼æ¥ï¼Œéœ€è¦æŠŠarticle_idä¿®æ”¹æˆclick_article_id
    item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})

    return item_info_df


# è¯»å–æ–‡ç« çš„Embeddingæ•°æ®
def get_item_emb_dict(data_path, save_path):
    pkl_path = os.path.join(save_path, 'item_content_emb.pkl')

    # âœ… å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¯»å–è¿”å›
    if os.path.exists(pkl_path):
        print("ğŸ”„ PKL file exists, loading directly...")  # å·²å­˜åœ¨ pkl æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½...
        with open(pkl_path, 'rb') as f:
            return pickle.load(f)

    # å¦åˆ™æ‰è®¡ç®—å¹¶ä¿å­˜
    print("ğŸ“¥ Reading CSV and computing embeddings...")  # æ­£åœ¨è¯»å– CSV å¹¶è®¡ç®— Embedding...
    item_emb_df = pd.read_csv(os.path.join(data_path, 'articles_emb.csv'))

    # embedding å‘é‡çš„å½’ä¸€åŒ–ï¼ˆæŒ‰è¡Œå•ä½åŒ–ï¼‰
    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]
    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols])
    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)

    item_emb_dict = dict(zip(item_emb_df['article_id'], item_emb_np))
    with open(pkl_path, 'wb') as f:
        pickle.dump(item_emb_dict, f)

    return item_emb_dict

# å‘é‡æ£€ç´¢ç›¸ä¼¼åº¦è®¡ç®—
# topkæŒ‡çš„æ˜¯æ¯ä¸ªitem, faissæœç´¢åè¿”å›æœ€ç›¸ä¼¼çš„topkä¸ªitem
def embdding_sim(click_df, item_emb_df, save_path, topk):
    """
        åŸºäºå†…å®¹çš„æ–‡ç« embeddingç›¸ä¼¼æ€§çŸ©é˜µè®¡ç®—
        :param click_df: æ•°æ®è¡¨
        :param item_emb_df: æ–‡ç« çš„embedding
        :param save_path: ä¿å­˜è·¯å¾„
        :patam topk: æ‰¾æœ€ç›¸ä¼¼çš„topkç¯‡
        return æ–‡ç« ç›¸ä¼¼æ€§çŸ©é˜µ

        æ€è·¯: å¯¹äºæ¯ä¸€ç¯‡æ–‡ç« ï¼Œ åŸºäºembeddingçš„ç›¸ä¼¼æ€§è¿”å›topkä¸ªä¸å…¶æœ€ç›¸ä¼¼çš„æ–‡ç« ï¼Œ åªä¸è¿‡ç”±äºæ–‡ç« æ•°é‡å¤ªå¤šï¼Œè¿™é‡Œç”¨äº†faissè¿›è¡ŒåŠ é€Ÿ
    """

    # æ–‡ç« ç´¢å¼•ä¸æ–‡ç« idçš„å­—å…¸æ˜ å°„
    item_idx_2_rawid_dict = dict(enumerate(item_emb_df['article_id'].values))

    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]
    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols].values, dtype=np.float32)
    # å‘é‡è¿›è¡Œå•ä½åŒ–
    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)

    # å»ºç«‹faissç´¢å¼•
    item_index = faiss.IndexFlatIP(item_emb_np.shape[1])
    item_index.add(item_emb_np) # type: ignore
    # ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼Œç»™æ¯ä¸ªç´¢å¼•ä½ç½®ä¸Šçš„å‘é‡è¿”å›topkä¸ªitemä»¥åŠç›¸ä¼¼åº¦
    sim, idx = item_index.search(item_emb_np, topk)  # type: ignore # è¿”å›çš„æ˜¯åˆ—è¡¨

    # å°†å‘é‡æ£€ç´¢çš„ç»“æœä¿å­˜æˆåŸå§‹idçš„å¯¹åº”å…³ç³»
    item_sim_dict = collections.defaultdict(dict)
    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(item_emb_np)), sim, idx)):
        target_raw_id = item_idx_2_rawid_dict[target_idx]
        # ä»1å¼€å§‹æ˜¯ä¸ºäº†å»æ‰å•†å“æœ¬èº«, æ‰€ä»¥æœ€ç»ˆè·å¾—çš„ç›¸ä¼¼å•†å“åªæœ‰topk-1
        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]):
            rele_raw_id = item_idx_2_rawid_dict[rele_idx]
            item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id,
                                                                                                 0) + sim_value

    # ä¿å­˜i2iç›¸ä¼¼åº¦çŸ©é˜µ
    pickle.dump(item_sim_dict, open(save_path + 'emb_i2i_sim.pkl', 'wb'))

    return item_sim_dict